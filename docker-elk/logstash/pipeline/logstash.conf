input {
	# 실행 명령어 : ./filebeat
	beats{
		port => 5000
	}

    # test : 테스트 로그를 localhost:5000 으로 전송하면 elasticsearch 가 입력 받는다
	# head -n 1 ./api.log | nc localhost 5000
	# tcp {
	# 	port => 5000
	# }

	# kafka {
    #    bootstrap_servers => "192.168.103.225:9094"
    #    topics => ["sweet_topic", "common_log_topic", "kakao_log_topic", "delivery_agent_topic"]
    #    codec => json
    #    decorate_events => true
    # }
}


filter {
	########### grok ###########
	# 로그를 파싱하여 엘라스틱 서치 필드로 저장하기 위한 필터
	# grok 패턴 사전 : https://github.com/elastic/logstash/blob/v1.4.2/patterns/grok-patterns
	# grok 패턴 테스트 : http://grokconstructor.appspot.com/do/match
	# grok 패턴 기본 : %{정규패턴명 : 엘라스틱서치에 저장되는 필드명}
	# 정규식을 사용하는 경우 : (?<엘라스틱서치에 저장되는 필드명>정규식)
	# 필터를 복수로 두는 경우 각각의 필드가 조합되어 엘라스틱 서치에 리턴된다

	grok {
    	patterns_dir => ['/usr/share/logstash/pipeline/patterns']
     	match => {"message" => "%{SOPS_PARSING_FAILED_LOG}"}
    }
	grok {
    	patterns_dir => ['/usr/share/logstash/pipeline/patterns']
		match => {"message" => "%{SOPS_DELV_ISSUE_LOG}"}
    }
	grok {
    	patterns_dir => ['/usr/share/logstash/pipeline/patterns']
		match => {"message" => "%{SOPS_NON_RESPONSE_OR_STANDARD_ERROR_LOG}"}
    }
	if ![shopCode]{
		grok {
    		patterns_dir => ['/usr/share/logstash/pipeline/patterns']
			match => {"message" => "%{SOPS_ERROR_LOG}"}
    	}
	}
	mutate {
		remove_field => [
			"message", "agent", "host", "log", "input", 
			"ecs", "tags", "@version", "logMethod", "time", "level"
		]
	}

#  	if [@metadata][kafka][topic] == "sopsV4" {
#		....
#    }

}

output {
	# 검색하기 : GET sops/_search 
	# issue 추출된 경우에만 return
	if [issue] {
		elasticsearch {
			hosts => "elasticsearch:9200"
			index => "sops"
			user => "elastic"
			password => "changeme"
		}
	}

	
#	if [@metadata][kafka][topic] == "sweet_topic" {
#		elasticsearch {
#			hosts => "http://elasticsearch:9200"
#			index => "sweet-elk"
#			user => "elastic"
#			password => "changeme"
#		}
#	} 
}
